{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Obtaining dependency information for ucimlrepo from https://files.pythonhosted.org/packages/85/8b/aab8a1c1344af158feb0b7f13d15ae184bc1e93625cea98d9c783b2e29d4/ucimlrepo-0.0.2-py3-none-any.whl.metadata\n",
      "  Downloading ucimlrepo-0.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading ucimlrepo-0.0.2-py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: ucimlrepo\n",
      "Successfully installed ucimlrepo-0.0.2\n"
     ]
    }
   ],
   "source": [
    "# ! pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Mon Jul 17 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'published_in': 'Electronic imaging', 'year': 1993, 'url': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'doi': '10.1117/12.148698'}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n"
     ]
    }
   ],
   "source": [
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer = fetch_ucirepo(id=14) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer.data.features \n",
    "y = breast_cancer.data.targets \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 14, 'name': 'Breast Cancer', 'repository_url': 'https://archive.ics.uci.edu/dataset/14/breast+cancer', 'data_url': 'https://archive.ics.uci.edu/static/public/14/data.csv', 'abstract': 'Breast Cancer Data (Restricted Access)', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 286, 'num_features': 9, 'feature_types': ['Categorical'], 'demographics': ['Age'], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1988, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C51P4M', 'creators': ['Matjaz Zwitter', 'Milan Soklic'], 'intro_paper': None, 'additional_info': {'summary': 'This is one of three domains provided by the Oncology Institute that has repeatedly appeared in the machine learning literature. (See also lymphography and primary-tumor.)\\r\\n\\r\\nThis data set includes 201 instances of one class and 85 instances of another class.  The instances are described by 9 attributes, some of which are linear and some are nominal.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '   1. Class: no-recurrence-events, recurrence-events\\r\\n   2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.\\r\\n   3. menopause: lt40, ge40, premeno.\\r\\n   4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, 45-49, 50-54, 55-59.\\r\\n   5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26, 27-29, 30-32, 33-35, 36-39.\\r\\n   6. node-caps: yes, no.\\r\\n   7. deg-malig: 1, 2, 3.\\r\\n   8. breast: left, right.\\r\\n   9. breast-quad: left-up, left-low, right-up,\\tright-low, central.\\r\\n  10. irradiat:\\tyes, no.', 'citation': None}}\n"
     ]
    }
   ],
   "source": [
    "# metadata \n",
    "print(breast_cancer.metadata) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name     role         type demographic  \\\n",
      "0        Class   Target       Binary        None   \n",
      "1          age  Feature  Categorical         Age   \n",
      "2    menopause  Feature  Categorical        None   \n",
      "3   tumor-size  Feature  Categorical        None   \n",
      "4    inv-nodes  Feature  Categorical        None   \n",
      "5    node-caps  Feature       Binary        None   \n",
      "6    deg-malig  Feature      Integer        None   \n",
      "7       breast  Feature       Binary        None   \n",
      "8  breast-quad  Feature  Categorical        None   \n",
      "9     irradiat  Feature       Binary        None   \n",
      "\n",
      "                                         description  units missing_values  \n",
      "0            no-recurrence-events, recurrence-events   None             no  \n",
      "1  10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-7...  years             no  \n",
      "2                                lt40, ge40, premeno   None             no  \n",
      "3  0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 3...   None             no  \n",
      "4   0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-...   None             no  \n",
      "5                                            yes, no   None            yes  \n",
      "6                                            1, 2, 3   None             no  \n",
      "7                                        left, right   None             no  \n",
      "8   left-up, left-low, right-up,\\tright-low, central   None            yes  \n",
      "9                                            yes, no   None             no  \n"
     ]
    }
   ],
   "source": [
    "# variable information \n",
    "print(breast_cancer.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. age: age in years\n",
    "2. sex: sex (1 = male; 0 = female)\n",
    "3. cp: chest pain type\n",
    "    - Value 1: typical angina\n",
    "    - Value 2: atypical angina\n",
    "    - Value 3: non-anginal pain\n",
    "    - Value 4: asymptomatic\n",
    "4. trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "5. chol: serum cholestoral in mg/dl\n",
    "6. fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n",
    "7. restecg: resting electrocardiographic results\n",
    "    - Value 0: normal\n",
    "    - Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "    - Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. thalach: maximum heart rate achieved\n",
    "9. exang: exercise induced angina (1 = yes; 0 = no)\n",
    "10. oldpeak = ST depression induced by exercise relative to rest\n",
    "11.  slope: the slope of the peak exercise ST segment\n",
    "    - Value 1: upsloping\n",
    "    - Value 2: flat\n",
    "    - Value 3: downsloping\n",
    "12. ca: number of major vessels (0-3) colored by flourosopy\n",
    "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "14. num: diagnosis of heart disease (angiographic disease status)\n",
    "    - Value 0: < 50% diameter narrowing\n",
    "    - Value 1: > 50% diameter narrowing\n",
    "        (in any major vessel: attributes 59 through 68 are vessels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   1       145   233    1        2      150      0      2.3   \n",
       "1     67    1   4       160   286    0        2      108      1      1.5   \n",
       "2     67    1   4       120   229    0        2      129      1      2.6   \n",
       "3     37    1   3       130   250    0        0      187      0      3.5   \n",
       "4     41    0   2       130   204    0        2      172      0      1.4   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   45    1   1       110   264    0        0      132      0      1.2   \n",
       "299   68    1   4       144   193    1        0      141      0      3.4   \n",
       "300   57    1   4       130   131    0        0      115      1      1.2   \n",
       "301   57    0   2       130   236    0        2      174      0      0.0   \n",
       "302   38    1   3       138   175    0        0      173      0      0.0   \n",
       "\n",
       "     slope   ca  thal  \n",
       "0        3  0.0   6.0  \n",
       "1        2  3.0   3.0  \n",
       "2        2  2.0   7.0  \n",
       "3        3  0.0   3.0  \n",
       "4        1  0.0   3.0  \n",
       "..     ...  ...   ...  \n",
       "298      2  0.0   7.0  \n",
       "299      2  2.0   7.0  \n",
       "300      2  1.0   7.0  \n",
       "301      2  1.0   3.0  \n",
       "302      1  NaN   3.0  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 45, 'name': 'Heart Disease', 'repository_url': 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'data_url': 'https://archive.ics.uci.edu/static/public/45/data.csv', 'abstract': '4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach', 'area': 'Life Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 303, 'num_features': 13, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': ['Age', 'Sex'], 'target_col': ['num'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1989, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C52P4X', 'creators': ['Andras Janosi', 'William Steinbrunn', 'Matthias Pfisterer', 'Robert Detrano'], 'intro_paper': {'title': 'International application of a new probability algorithm for the diagnosis of coronary artery disease.', 'authors': 'R. Detrano, A. Jánosi, W. Steinbrunn, M. Pfisterer, J. Schmid, S. Sandhu, K. Guppy, S. Lee, V. Froelicher', 'published_in': 'American Journal of Cardiology', 'year': 1989, 'url': 'https://www.semanticscholar.org/paper/a7d714f8f87bfc41351eb5ae1e5472f0ebbe0574', 'doi': None}, 'additional_info': {'summary': 'This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \\n   \\nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\\n\\nOne file has been \"processed\", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.\\n\\nTo see Test Costs (donated by Peter Turney), please see the folder \"Costs\" ', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Only 14 attributes used:\\r\\n      1. #3  (age)       \\r\\n      2. #4  (sex)       \\r\\n      3. #9  (cp)        \\r\\n      4. #10 (trestbps)  \\r\\n      5. #12 (chol)      \\r\\n      6. #16 (fbs)       \\r\\n      7. #19 (restecg)   \\r\\n      8. #32 (thalach)   \\r\\n      9. #38 (exang)     \\r\\n      10. #40 (oldpeak)   \\r\\n      11. #41 (slope)     \\r\\n      12. #44 (ca)        \\r\\n      13. #51 (thal)      \\r\\n      14. #58 (num)       (the predicted attribute)\\r\\n\\r\\nComplete attribute documentation:\\r\\n      1 id: patient identification number\\r\\n      2 ccf: social security number (I replaced this with a dummy value of 0)\\r\\n      3 age: age in years\\r\\n      4 sex: sex (1 = male; 0 = female)\\r\\n      5 painloc: chest pain location (1 = substernal; 0 = otherwise)\\r\\n      6 painexer (1 = provoked by exertion; 0 = otherwise)\\r\\n      7 relrest (1 = relieved after rest; 0 = otherwise)\\r\\n      8 pncaden (sum of 5, 6, and 7)\\r\\n      9 cp: chest pain type\\r\\n        -- Value 1: typical angina\\r\\n        -- Value 2: atypical angina\\r\\n        -- Value 3: non-anginal pain\\r\\n        -- Value 4: asymptomatic\\r\\n     10 trestbps: resting blood pressure (in mm Hg on admission to the hospital)\\r\\n     11 htn\\r\\n     12 chol: serum cholestoral in mg/dl\\r\\n     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\\r\\n     14 cigs (cigarettes per day)\\r\\n     15 years (number of years as a smoker)\\r\\n     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\\r\\n     17 dm (1 = history of diabetes; 0 = no such history)\\r\\n     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\\r\\n     19 restecg: resting electrocardiographic results\\r\\n        -- Value 0: normal\\r\\n        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\\r\\n        -- Value 2: showing probable or definite left ventricular hypertrophy by Estes\\' criteria\\r\\n     20 ekgmo (month of exercise ECG reading)\\r\\n     21 ekgday(day of exercise ECG reading)\\r\\n     22 ekgyr (year of exercise ECG reading)\\r\\n     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\\r\\n     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\\r\\n     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\\r\\n     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\\r\\n     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\\r\\n     28 proto: exercise protocol\\r\\n          1 = Bruce     \\r\\n          2 = Kottus\\r\\n          3 = McHenry\\r\\n          4 = fast Balke\\r\\n          5 = Balke\\r\\n          6 = Noughton \\r\\n          7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was written!)\\r\\n          8 = bike 125 kpa min/min  \\r\\n          9 = bike 100 kpa min/min\\r\\n         10 = bike 75 kpa min/min\\r\\n         11 = bike 50 kpa min/min\\r\\n         12 = arm ergometer\\r\\n     29 thaldur: duration of exercise test in minutes\\r\\n     30 thaltime: time when ST measure depression was noted\\r\\n     31 met: mets achieved\\r\\n     32 thalach: maximum heart rate achieved\\r\\n     33 thalrest: resting heart rate\\r\\n     34 tpeakbps: peak exercise blood pressure (first of 2 parts)\\r\\n     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\\r\\n     36 dummy\\r\\n     37 trestbpd: resting blood pressure\\r\\n     38 exang: exercise induced angina (1 = yes; 0 = no)\\r\\n     39 xhypo: (1 = yes; 0 = no)\\r\\n     40 oldpeak = ST depression induced by exercise relative to rest\\r\\n     41 slope: the slope of the peak exercise ST segment\\r\\n        -- Value 1: upsloping\\r\\n        -- Value 2: flat\\r\\n        -- Value 3: downsloping\\r\\n     42 rldv5: height at rest\\r\\n     43 rldv5e: height at peak exercise\\r\\n     44 ca: number of major vessels (0-3) colored by flourosopy\\r\\n     45 restckm: irrelevant\\r\\n     46 exerckm: irrelevant\\r\\n     47 restef: rest raidonuclid (sp?) ejection fraction\\r\\n     48 restwm: rest wall (sp?) motion abnormality\\r\\n        0 = none\\r\\n        1 = mild or moderate\\r\\n        2 = moderate or severe\\r\\n        3 = akinesis or dyskmem (sp?)\\r\\n     49 exeref: exercise radinalid (sp?) ejection fraction\\r\\n     50 exerwm: exercise wall (sp?) motion \\r\\n     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\\r\\n     52 thalsev: not used\\r\\n     53 thalpul: not used\\r\\n     54 earlobe: not used\\r\\n     55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\\r\\n     56 cday: day of cardiac cath (sp?)\\r\\n     57 cyr: year of cardiac cath (sp?)\\r\\n     58 num: diagnosis of heart disease (angiographic disease status)\\r\\n        -- Value 0: < 50% diameter narrowing\\r\\n        -- Value 1: > 50% diameter narrowing\\r\\n        (in any major vessel: attributes 59 through 68 are vessels)\\r\\n     59 lmt\\r\\n     60 ladprox\\r\\n     61 laddist\\r\\n     62 diag\\r\\n     63 cxmain\\r\\n     64 ramus\\r\\n     65 om1\\r\\n     66 om2\\r\\n     67 rcaprox\\r\\n     68 rcadist\\r\\n     69 lvx1: not used\\r\\n     70 lvx2: not used\\r\\n     71 lvx3: not used\\r\\n     72 lvx4: not used\\r\\n     73 lvf: not used\\r\\n     74 cathef: not used\\r\\n     75 junk: not used\\r\\n     76 name: last name of patient  (I replaced this with the dummy string \"name\")', 'citation': None}}\n"
     ]
    }
   ],
   "source": [
    "# metadata \n",
    "print(heart_disease.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name     role         type demographic  \\\n",
      "0        age  Feature      Integer         Age   \n",
      "1        sex  Feature  Categorical         Sex   \n",
      "2         cp  Feature  Categorical        None   \n",
      "3   trestbps  Feature      Integer        None   \n",
      "4       chol  Feature      Integer        None   \n",
      "5        fbs  Feature  Categorical        None   \n",
      "6    restecg  Feature  Categorical        None   \n",
      "7    thalach  Feature      Integer        None   \n",
      "8      exang  Feature  Categorical        None   \n",
      "9    oldpeak  Feature      Integer        None   \n",
      "10     slope  Feature  Categorical        None   \n",
      "11        ca  Feature      Integer        None   \n",
      "12      thal  Feature  Categorical        None   \n",
      "13       num   Target      Integer        None   \n",
      "\n",
      "                                          description  units missing_values  \n",
      "0                                                None  years             no  \n",
      "1                                                None   None             no  \n",
      "2                                                None   None             no  \n",
      "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
      "4                                   serum cholestoral  mg/dl             no  \n",
      "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
      "6                                                None   None             no  \n",
      "7                         maximum heart rate achieved   None             no  \n",
      "8                             exercise induced angina   None             no  \n",
      "9   ST depression induced by exercise relative to ...   None             no  \n",
      "10                                               None   None             no  \n",
      "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
      "12                                               None   None            yes  \n",
      "13                         diagnosis of heart disease   None             no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# variable information \n",
    "print(heart_disease.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\"GHO\",\"PUBLISHSTATE\",\"YEAR\",\"REGION\",\"COUNTRY\",\"SEX\",\"Display Value\",\"Numeric\",\"Low\",\"High\",\"StdErr\",\"StdDev\",\"Comments\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2000\",\"AFR\",\"BWA\",\"MLE\",\"43.9\",\"43.89779\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2010\",\"AFR\",\"BWA\",\"MLE\",\"55.1\",\"55.14339\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2015\",\"AFR\",\"BWA\",\"MLE\",\"57.8\",\"57.82610\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2019\",\"AFR\",\"BWA\",\"MLE\",\"58.9\",\"58.94968\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2000\",\"AFR\",\"BWA\",\"FMLE\",\"47.8\",\"47.76789\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2010\",\"AFR\",\"BWA\",\"FMLE\",\"61.4\",\"61.35551\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2015\",\"AFR\",\"BWA\",\"FMLE\",\"63.9\",\"63.92690\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2019\",\"AFR\",\"BWA\",\"FMLE\",\"65.5\",\"65.45545\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2000\",\"AFR\",\"BWA\",\"BTSX\",\"45.6\",\"45.58516\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2010\",\"AFR\",\"BWA\",\"BTSX\",\"58.1\",\"58.13730\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2015\",\"AFR\",\"BWA\",\"BTSX\",\"60.9\",\"60.92577\",\"\",\"\",\"\",\"\",\"\"\\n\"WHOSIS_000001\",\"PUBLISHED\",\"2019\",\"AFR\",\"BWA\",\"BTSX\",\"62.2\",\"62.24785\",\"\",\"\",\"\",\"\",\"\"\\n'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the API you want to request\n",
    "url = \"http://apps.who.int/gho/athena/api/GHO/WHOSIS_000001.csv?filter=COUNTRY:BWA\"\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the response content\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the URL of the API you want to request\n",
    "url = \"http://apps.who.int/gho/athena/api/GHO/WHOSIS_000001.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'requests.models.Response'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASUS\\My_Journal\\ML\\ML-homework\\ml_project\\dataset.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ASUS/My_Journal/ML/ML-homework/ml_project/dataset.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/My_Journal/ML/ML-homework/ml_project/dataset.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(response)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    715\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    717\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    719\u001b[0m     path_or_buf,\n\u001b[0;32m    720\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    721\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    722\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    723\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    724\u001b[0m )\n\u001b[0;32m    726\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    727\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\envs\\ML_env\\lib\\site-packages\\pandas\\io\\common.py:460\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[0;32m    457\u001b[0m     \u001b[39mhasattr\u001b[39m(filepath_or_buffer, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(filepath_or_buffer, \u001b[39m\"\u001b[39m\u001b[39mwrite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    458\u001b[0m ):\n\u001b[0;32m    459\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid file path or buffer object type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(filepath_or_buffer)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    462\u001b[0m \u001b[39mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    463\u001b[0m     filepath_or_buffer\u001b[39m=\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    464\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    467\u001b[0m     mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    468\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'requests.models.Response'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                GHO PUBLISHSTATE  YEAR  REGION WORLDBANKINCOMEGROUP COUNTRY  \\\n",
      "0     WHOSIS_000001    PUBLISHED  2000     EMR                  NaN     AFG   \n",
      "1     WHOSIS_000001    PUBLISHED  2010     EMR                  NaN     AFG   \n",
      "2     WHOSIS_000001    PUBLISHED  2015     EMR                  NaN     AFG   \n",
      "3     WHOSIS_000001    PUBLISHED  2019     EMR                  NaN     AFG   \n",
      "4     WHOSIS_000001    PUBLISHED  2000     EMR                  NaN     AFG   \n",
      "...             ...          ...   ...     ...                  ...     ...   \n",
      "2323  WHOSIS_000001    PUBLISHED  2019  GLOBAL      WB_WORLD_INCOME     NaN   \n",
      "2324  WHOSIS_000001    PUBLISHED  2000  GLOBAL      WB_WORLD_INCOME     NaN   \n",
      "2325  WHOSIS_000001    PUBLISHED  2010  GLOBAL      WB_WORLD_INCOME     NaN   \n",
      "2326  WHOSIS_000001    PUBLISHED  2015  GLOBAL      WB_WORLD_INCOME     NaN   \n",
      "2327  WHOSIS_000001    PUBLISHED  2019  GLOBAL      WB_WORLD_INCOME     NaN   \n",
      "\n",
      "       SEX  Display Value   Numeric  Low  High  StdErr  StdDev  Comments  \n",
      "0      MLE           54.6  54.57449  NaN   NaN     NaN     NaN       NaN  \n",
      "1      MLE           59.6  59.60036  NaN   NaN     NaN     NaN       NaN  \n",
      "2      MLE           61.0  61.03658  NaN   NaN     NaN     NaN       NaN  \n",
      "3      MLE           63.3  63.28709  NaN   NaN     NaN     NaN       NaN  \n",
      "4     FMLE           55.4  55.41726  NaN   NaN     NaN     NaN       NaN  \n",
      "...    ...            ...       ...  ...   ...     ...     ...       ...  \n",
      "2323  FMLE           75.9  75.87223  NaN   NaN     NaN     NaN       NaN  \n",
      "2324  BTSX           66.8  66.79430  NaN   NaN     NaN     NaN       NaN  \n",
      "2325  BTSX           70.5  70.52787  NaN   NaN     NaN     NaN       NaN  \n",
      "2326  BTSX           72.3  72.27778  NaN   NaN     NaN     NaN       NaN  \n",
      "2327  BTSX           73.3  73.31331  NaN   NaN     NaN     NaN       NaN  \n",
      "\n",
      "[2328 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Make a request to the API\n",
    "response = requests.get(\"http://apps.who.int/gho/athena/api/GHO/WHOSIS_000001.csv\")\n",
    "\n",
    "# Step 2: Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Step 3: Get the CSV data\n",
    "    data = response.text\n",
    "\n",
    "    # Step 4: Save it to a file\n",
    "    with open('data.csv', 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    # Step 5: Load it into Python\n",
    "    df = pd.read_csv('data.csv')\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Error fetching data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHO</th>\n",
       "      <th>PUBLISHSTATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>REGION</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>SEX</th>\n",
       "      <th>Display Value</th>\n",
       "      <th>Numeric</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>StdErr</th>\n",
       "      <th>StdDev</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2000</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>MLE</td>\n",
       "      <td>43.9</td>\n",
       "      <td>43.89779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2010</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>MLE</td>\n",
       "      <td>55.1</td>\n",
       "      <td>55.14339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2015</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>MLE</td>\n",
       "      <td>57.8</td>\n",
       "      <td>57.82610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2019</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>MLE</td>\n",
       "      <td>58.9</td>\n",
       "      <td>58.94968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2000</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>FMLE</td>\n",
       "      <td>47.8</td>\n",
       "      <td>47.76789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2010</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>FMLE</td>\n",
       "      <td>61.4</td>\n",
       "      <td>61.35551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2015</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>FMLE</td>\n",
       "      <td>63.9</td>\n",
       "      <td>63.92690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2019</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>FMLE</td>\n",
       "      <td>65.5</td>\n",
       "      <td>65.45545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2000</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>BTSX</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45.58516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2010</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>BTSX</td>\n",
       "      <td>58.1</td>\n",
       "      <td>58.13730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2015</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>BTSX</td>\n",
       "      <td>60.9</td>\n",
       "      <td>60.92577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WHOSIS_000001</td>\n",
       "      <td>PUBLISHED</td>\n",
       "      <td>2019</td>\n",
       "      <td>AFR</td>\n",
       "      <td>BWA</td>\n",
       "      <td>BTSX</td>\n",
       "      <td>62.2</td>\n",
       "      <td>62.24785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GHO PUBLISHSTATE  YEAR REGION COUNTRY   SEX  Display Value  \\\n",
       "0   WHOSIS_000001    PUBLISHED  2000    AFR     BWA   MLE           43.9   \n",
       "1   WHOSIS_000001    PUBLISHED  2010    AFR     BWA   MLE           55.1   \n",
       "2   WHOSIS_000001    PUBLISHED  2015    AFR     BWA   MLE           57.8   \n",
       "3   WHOSIS_000001    PUBLISHED  2019    AFR     BWA   MLE           58.9   \n",
       "4   WHOSIS_000001    PUBLISHED  2000    AFR     BWA  FMLE           47.8   \n",
       "5   WHOSIS_000001    PUBLISHED  2010    AFR     BWA  FMLE           61.4   \n",
       "6   WHOSIS_000001    PUBLISHED  2015    AFR     BWA  FMLE           63.9   \n",
       "7   WHOSIS_000001    PUBLISHED  2019    AFR     BWA  FMLE           65.5   \n",
       "8   WHOSIS_000001    PUBLISHED  2000    AFR     BWA  BTSX           45.6   \n",
       "9   WHOSIS_000001    PUBLISHED  2010    AFR     BWA  BTSX           58.1   \n",
       "10  WHOSIS_000001    PUBLISHED  2015    AFR     BWA  BTSX           60.9   \n",
       "11  WHOSIS_000001    PUBLISHED  2019    AFR     BWA  BTSX           62.2   \n",
       "\n",
       "     Numeric  Low  High  StdErr  StdDev  Comments  \n",
       "0   43.89779  NaN   NaN     NaN     NaN       NaN  \n",
       "1   55.14339  NaN   NaN     NaN     NaN       NaN  \n",
       "2   57.82610  NaN   NaN     NaN     NaN       NaN  \n",
       "3   58.94968  NaN   NaN     NaN     NaN       NaN  \n",
       "4   47.76789  NaN   NaN     NaN     NaN       NaN  \n",
       "5   61.35551  NaN   NaN     NaN     NaN       NaN  \n",
       "6   63.92690  NaN   NaN     NaN     NaN       NaN  \n",
       "7   65.45545  NaN   NaN     NaN     NaN       NaN  \n",
       "8   45.58516  NaN   NaN     NaN     NaN       NaN  \n",
       "9   58.13730  NaN   NaN     NaN     NaN       NaN  \n",
       "10  60.92577  NaN   NaN     NaN     NaN       NaN  \n",
       "11  62.24785  NaN   NaN     NaN     NaN       NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
