{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [example data](#toc1_)    \n",
    "- [basic components](#toc2_)    \n",
    "  - [Dataloader](#toc2_1_)    \n",
    "  - [define layer](#toc2_2_)    \n",
    "  - [define loss](#toc2_3_)    \n",
    "  - [define optimizer == gradient descent](#toc2_4_)    \n",
    "- [learning](#toc3_)    \n",
    "- [try real dataset](#toc4_)    \n",
    "  - [Dataloader](#toc4_1_)    \n",
    "  - [model](#toc4_2_)    \n",
    "  - [training](#toc4_3_)    \n",
    "  - [Testing](#toc4_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") # cpu or cuda\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[example data](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m,n -> 5,3   \n",
    "y -> (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Input (temp, rainfall, humidity)\n",
    "X_train = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "Y_train = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs =torch.from_numpy(X_train)\n",
    "targets = torch.from_numpy(Y_train)\n",
    "\n",
    "type(inputs), type(targets) # torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[basic components](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Dataloader](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([73., 67., 43.]), tensor([56., 70.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(inputs,targets)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 3\n",
    "train_dl = DataLoader(train_dataset,batch_size,shuffle = False,num_workers=4) # shuffle should be True commonly you would want randomness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.]])\n",
      "==========\n",
      "tensor([[102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 73.,  67.,  43.]])\n",
      "tensor([[ 22.,  37.],\n",
      "        [103., 119.],\n",
      "        [ 56.,  70.]])\n",
      "==========\n",
      "tensor([[ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.]])\n",
      "tensor([[ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.]])\n",
      "==========\n",
      "tensor([[69., 96., 70.],\n",
      "        [73., 67., 43.],\n",
      "        [91., 88., 64.]])\n",
      "tensor([[103., 119.],\n",
      "        [ 56.,  70.],\n",
      "        [ 81., 101.]])\n",
      "==========\n",
      "tensor([[ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_dl:\n",
    "    print(\"=\"*10)\n",
    "    print(X)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[define layer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5331,  0.0341, -0.3684],\n",
      "        [ 0.2660,  0.2188, -0.1042]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "Parameter containing:\n",
      "tensor([-0.3903,  0.2751], requires_grad=True)\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(layer.weight)\n",
    "print(layer.weight.shape)\n",
    "print(layer.bias)\n",
    "print(layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = layer(inputs)\n",
    "# (15,3) @ (3,2) => (15,2)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.5331,  0.0341, -0.3684],\n",
      "        [ 0.2660,  0.2188, -0.1042]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3903,  0.2751], requires_grad=True)\n",
      "total param = 8\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for param in layer.parameters():\n",
    "    print(param)\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"total param = {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[define loss](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12288.3438, grad_fn=<MseLossBackward0>), 12288.34375)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = criterion(targets,outputs)\n",
    "mse,mse.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[define optimizer == gradient descent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(layer.parameters(),lr = 0.0001,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[learning](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. for each epoch loop each batch  \n",
    "2. calculate output each batch  \n",
    "3. compare use loss function  \n",
    "4. cal gradient or step  \n",
    "5. update  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -8987.1553, -10930.8652,  -5963.0078],\n",
      "        [ -5426.0518,  -6749.8057,  -3609.3916]])\n",
      "tensor([[7982.0811, 6565.8457, 4813.4258],\n",
      "        [5886.3369, 4282.3770, 3184.8538]])\n",
      "tensor([[13520.0605, 13558.4980,  7899.5293],\n",
      "        [ 8004.2021,  7331.7725,  4446.8135]])\n",
      "tensor([[-8258.9102, -9007.4883, -6392.8276],\n",
      "        [-5804.2354, -6414.4336, -4564.1934]])\n",
      "tensor([[-12928.3389, -14509.6533,  -8479.1504],\n",
      "        [ -6600.6025,  -7894.0820,  -4566.8721]])\n",
      "epoch 1: 14974.38\n",
      "tensor([[ 9230.2529, 11177.5762,  6120.7539],\n",
      "        [ 6188.8853,  7475.1304,  4098.7227]])\n",
      "tensor([[7239.4448, 6968.9258, 5024.8555],\n",
      "        [3838.1812, 3580.1328, 2587.7407]])\n",
      "tensor([[-2834.3872, -1781.9666, -1339.0400],\n",
      "        [-2774.8772, -2144.1343, -1453.2002]])\n",
      "tensor([[-7273.5254, -7759.3281, -5486.3457],\n",
      "        [-3980.1348, -4232.3906, -2992.8855]])\n",
      "tensor([[-1099.9762,   272.0613,  -111.5534],\n",
      "        [  735.5317,  2000.4954,   922.2926]])\n",
      "epoch 2: 930.21\n",
      "tensor([[7634.3970, 9400.5059, 5069.9668],\n",
      "        [3804.5369, 4840.4614, 2527.3486]])\n",
      "tensor([[-2063.0605,  -974.4769,  -776.6316],\n",
      "        [-2741.9817, -1736.7478, -1319.2861]])\n",
      "tensor([[-7307.5664, -6634.0537, -4039.1709],\n",
      "        [-4099.0688, -3333.9316, -2168.3689]])\n",
      "tensor([[2063.2529, 2329.8147, 1664.5183],\n",
      "        [2239.4941, 2522.6831, 1799.1084]])\n",
      "tensor([[4977.9531, 6052.2642, 3498.8975],\n",
      "        [3043.1343, 3999.9790, 2238.8933]])\n",
      "epoch 3: 2771.25\n",
      "tensor([[-2012.5812, -2521.0386, -1331.1267],\n",
      "        [-2582.8232, -3056.4180, -1710.1427]])\n",
      "tensor([[-3074.5610, -2840.3062, -2056.1321],\n",
      "        [-2124.6130, -1860.5994, -1354.4241]])\n",
      "tensor([[ -864.2430, -1589.9231,  -678.1205],\n",
      "        [  981.7501,   726.1763,   508.3713]])\n",
      "tensor([[3796.1997, 4039.5811, 2857.9224],\n",
      "        [2181.6531, 2331.1992, 1649.2579]])\n",
      "tensor([[1566.4287,  655.2181,  653.4006],\n",
      "        [-145.5521, -834.6282, -331.8067]])\n",
      "epoch 4: 479.83\n",
      "tensor([[-3312.0322, -4345.1333, -2199.7886],\n",
      "        [-2076.5918, -2690.4365, -1380.3674]])\n",
      "tensor([[1163.0673,  386.1493,  332.9712],\n",
      "        [1616.2533,  993.9802,  759.6705]])\n",
      "tensor([[2073.6792, 1083.3921,  951.7602],\n",
      "        [1905.4229, 1272.9937,  936.3076]])\n",
      "tensor([[  -20.8073,  -117.0500,   -91.8955],\n",
      "        [ -967.7741, -1108.8926,  -792.7864]])\n",
      "tensor([[-1478.1531, -2420.2930, -1228.8320],\n",
      "        [-1449.0938, -2175.1138, -1143.7334]])\n",
      "epoch 5: 618.50\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(3,2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(layer.parameters(),lr = 0.0001,momentum = 0.9)\n",
    "\n",
    "# define hyper param\n",
    "num_epochs = 5\n",
    "display_every = 1\n",
    "\n",
    "\n",
    "# loop epoch\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # loop mini batch\n",
    "    for batch_x,batch_y in train_dl:\n",
    "\n",
    "        # put data to gpu if you using gpu\n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "\n",
    "        # predict \n",
    "        yhat = layer(batch_x)\n",
    "\n",
    "        # cal loss\n",
    "        loss = criterion(yhat,batch_y)\n",
    "\n",
    "        # cal grad\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    \n",
    "        print(layer.weight.grad)\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch%display_every == 0:\n",
    "        print(f\"epoch {epoch+1}: {loss:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[try real dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¦†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "print(data.feature_names)\n",
    "\n",
    "X,y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([331, 10]),\n",
       " torch.Size([331]),\n",
       " torch.Size([111, 10]),\n",
       " torch.Size([111]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data to float 32 because model weight is float32\n",
    "train_input= torch.tensor(X_train,dtype=torch.float32)\n",
    "train_output = torch.tensor(y_train,dtype=torch.float32)\n",
    "test_input = torch.tensor(X_test,dtype=torch.float32)\n",
    "test_output = torch.tensor(y_test,dtype=torch.float32)\n",
    "\n",
    "train_input.shape,train_output.shape,test_input.shape,test_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Dataloader](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(train_input,train_output)\n",
    "test_ds = TensorDataset(test_input,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=batch_size,shuffle=True,num_workers=4)\n",
    "test_dl = DataLoader(test_ds,batch_size=batch_size,shuffle=True,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_x,batch_y in train_dl:\n",
    "#     print(\"batch_x: \",batch_x.shape)\n",
    "#     print(\"batch_y: \",batch_y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequential => stack of layer but it can't use only linear because actually it not different from use 1 linear\n",
    "layer => basically dot product\n",
    "activation => sigmoid, tanh, relu, leaky relu \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24,12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12,6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6,1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total param: 649\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "for param in model.parameters():\n",
    "    total += param.numel()\n",
    "\n",
    "print(f\"total param: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#always good to test your neural network before training\n",
    "yhat = model(train_input)\n",
    "assert yhat.shape[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[training](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define save path\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = \"models/ann\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path,exist_ok=True)\n",
    "\n",
    "save_path = Path(file_path,\"diabetes.pth\")\n",
    "check_path = Path(file_path,\"diabetes_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\ASUS\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | 22849.40\n",
      "epoch 11 | 47688.19\n",
      "epoch 21 | 31080.00\n",
      "epoch 31 | 13929.93\n",
      "epoch 41 | 5119.35\n",
      "epoch 51 | 6010.41\n",
      "epoch 61 | 6263.44\n",
      "epoch 71 | 4858.86\n",
      "epoch 81 | 4205.63\n",
      "epoch 91 | 9103.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = 0.01\n",
    "display_every = 10\n",
    "num_epochs = 100\n",
    "lowest_loss = np.inf\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_x,batch_y in train_dl:\n",
    "\n",
    "        batch_x.to(device)\n",
    "        batch_y.to(device)\n",
    "\n",
    "        yhat = model(batch_x)\n",
    "\n",
    "        loss = criterion(yhat,batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if lowest_loss > loss.item():\n",
    "        lowest_loss = loss.item()\n",
    "        torch.save(model.state_dict(),check_path)\n",
    "\n",
    "    if epoch%display_every == display_every-1:\n",
    "        print(f\"epoch {epoch+1} | {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "best_val = np.inf\n",
    "\n",
    "for i in range(num_epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_samples = 0\n",
    "\n",
    "    for images, labels in train_dl:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_hat = model(images)\n",
    "        loss = criterion(y_hat, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (torch.max(y_hat, 1)[1] == labels).sum().item()\n",
    "        train_samples += len(images)\n",
    "\n",
    "    epoch_train_loss = train_loss / len(train_dl)\n",
    "    epoch_train_acc = (train_correct / train_samples) * 100\n",
    "\n",
    "    print(f\"Epoch: {i} | Train acc: {epoch_train_acc:3.2f} | Train Loss: {epoch_train_loss:3.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manual save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_4_'></a>[Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  #change the model to eval mode - it will skip dropout, batch norm\n",
    "total_avg_mse = 0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_x, batch_y in test_dl:\n",
    "        \n",
    "        yhat = model(batch_x)\n",
    "        batch_y = batch_y.reshape((-1, 1))\n",
    "        mse  = criterion(yhat, batch_y)\n",
    "        \n",
    "        total_avg_mse += mse.item() / len(test_dl)\n",
    "        \n",
    "print(\"Total Average MSE: \", total_avg_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
