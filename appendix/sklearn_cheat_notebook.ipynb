{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook try to summerize useful command in minimal way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('') # datapath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # see data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # see over all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # see data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: for classification problem you should always use hua = 'y' which 'y' is label name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"catagory data\") # see the number of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"continuous_data\", y=\"continuous_data\",hue='y') # see the relation between feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"continuous_data\") # see the distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"catagory_data or y\", y=\"continuous_data\") # see the distibution over catagory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = df ,x = 'y', y = \"continuous_data\", hue=\"y\") # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "easy for any task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue = 'y') # see the distribution and scaterplot and also can do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True) # see the correation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore as pps\n",
    "\n",
    "# before using pps, let's drop country and year\n",
    "dfcopy = df.copy()\n",
    "dfcopy.drop(['catagory_data1','catagory_data2'], axis='columns', inplace=True)\n",
    "\n",
    "#this needs some minor preprocessing because seaborn.heatmap unfortunately does not accept tidy data\n",
    "matrix_df = pps.matrix(dfcopy)[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "#plot\n",
    "plt.figure(figsize = (15,8))\n",
    "sns.heatmap(matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "have you ever try this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz\n",
    "report = sweetviz.analyze([df,'train'],target_feat='target_name')\n",
    "report.show_html('report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the meaning of data from what you get from eda ex cartesian to polar, take log, different value, grouping .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot again to see new feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splite\n",
    "X = df[['feature1','feature1']]\n",
    "y = df[\"y\"]\n",
    "# use all feature \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 96, stratify=y)\n",
    "# used satify to split balancly on y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isna().sum() # check null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts() # check catagory value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the outlier percentage\n",
    "def outlier_count(col, data = X_train):\n",
    "    \n",
    "    # calculate your 25% quatile and 75% quatile\n",
    "    q75, q25 = np.percentile(data[col], [75, 25])\n",
    "    \n",
    "    # calculate your inter quatile\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # min_val and max_val\n",
    "    min_val = q25 - (iqr*1.5)\n",
    "    max_val = q75 + (iqr*1.5)\n",
    "    \n",
    "    # count number of outliers, which are the data that are less than min_val or more than max_val calculated above\n",
    "    outlier_count = len(np.where((data[col] > max_val) | (data[col] < min_val))[0])\n",
    "    \n",
    "    # calculate the percentage of the outliers\n",
    "    outlier_percent = round(outlier_count/len(data[col])*100, 2)\n",
    "    \n",
    "    if(outlier_count > 0):\n",
    "        print(\"\\n\"+15*'-' + col + 15*'-'+\"\\n\")\n",
    "        print('Number of outliers: {}'.format(outlier_count))\n",
    "        print('Percent of data that is outlier: {}%'.format(outlier_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# feature scaling helps improve reach convergence faster\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use x1\n",
    "#any random_state you can use......up to you \n",
    "lr = LogisticRegression(random_state=96)\n",
    "rf = RandomForestClassifier(random_state=96)\n",
    "sv = SVC(random_state=96)\n",
    "gnb = GaussianNB()\n",
    "\n",
    "models = [lr, rf, sv,gnb]\n",
    "\n",
    "#3.2 perform cross validation using KFold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state=999)\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')  #f1, recall, precision, accuracy\n",
    "    print(\"Scores: \", score, \"- Scores mean: \", score.mean(), \"- Scores std (lower better): \", score.std())  #out of 1 ; 1 means perfect accuracy\n",
    "    #lr, rf, sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Offline upsampling could look like this:\n",
    "#first upsample / downsample\n",
    "smote = SMOTE(random_state = 11)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#then do scaling + modeling\n",
    "pipeline = Pipeline(steps = [['scaler', MinMaxScaler()], ['classifier', LogisticRegression(random_state=11, max_iter=1000)]])\n",
    "\n",
    "param_grid = {'C': [1, 10], 'kernel': ('linear', 'rbf')}\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state=999) \n",
    "grid_search = GridSearchCV(estimator=pipeline,  param_grid=param_grid, scoring='roc_auc', cv=kfold,  n_jobs=-1)\n",
    "\n",
    "# Online upsampling could look like this:\n",
    "\n",
    "#put smote as pipeline\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(random_state=11)], ['scaler', MinMaxScaler()], ['classifier', LogisticRegression(random_state=11,  max_iter=1000)]])\n",
    "\n",
    "param_grid = {'C': [1, 10], 'kernel': ('linear', 'rbf')}\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state=999)\n",
    "grid_search = GridSearchCV(estimator=pipeline,  param_grid=param_grid, scoring='roc_auc', cv=kfold,  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'bootstrap': [True], 'max_depth': [5, 10, None],\n",
    "              'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 1)\n",
    "\n",
    "grid = GridSearchCV(estimator = rf, \n",
    "                    param_grid = param_grid, \n",
    "                    cv = kfold, \n",
    "                    n_jobs = -1, \n",
    "                    return_train_score=True, \n",
    "                    refit=True,\n",
    "                    scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit your grid_search\n",
    "grid.fit(X_train, y_train);  #fit means start looping all the possible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = grid.best_estimator_\n",
    "\n",
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
